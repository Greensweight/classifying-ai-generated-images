{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786daa2f",
   "metadata": {},
   "source": [
    "# CPE695 Final Project for Team 1: <br>\n",
    "**Group Members**: Ronald \"Joey\" Rupert, Andrew Greensweight, Michael Salek <br><br>\n",
    "**Problem Statement:** <br>\n",
    "The quality of AI-generated images has rapidly increased, leading to concerns of authenticity and trustworthiness. The aim of this project is to investigate whether computer vision techniques can effectively detect when images have been generated by AI. By addressing this problem, we can contribute to the development of algorithms that enhance the authenticity verification of images.\n",
    "<br>\n",
    "<br>\n",
    "**Information on Dataset:** <br>\n",
    " https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\n",
    "The dataset contains two classes - REAL and FAKE. For REAL, the images are collected from Krizhevsky & Hinton's CIFAR-10 dataset. For the FAKE images, they were generated to be the  equivalent of CIFAR-10 with Stable Diffusion version 1.4.There are 100,000 images for training (50k per class) and 20,000 for testing (10k per class).\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca69ffa8",
   "metadata": {},
   "source": [
    "The below code reads in all of the images and resizes them to all be the same size\n",
    "\n",
    "This utilizes 5000 Fake and 5000 Real images for training and 1500 Fake and 1500 Real for testing\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecced8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading... training category : FAKE\n",
      "loaded training category:FAKE successfully\n",
      "loading... training category : REAL\n",
      "loaded training category:REAL successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Creates the target categories\n",
    "Categories=['FAKE','REAL']\n",
    "flat_data_arr_train=[] #input array\n",
    "target_arr_train=[] #output array\n",
    "\n",
    "#path which contains all of the training images\n",
    "datadir_train = \"C:/Users/Msalek/Documents/Stevens/EE695/Final Project/Code/train\"\n",
    "\n",
    "#Reads in the images from the selected file directory\n",
    "for i in Categories:\n",
    "    print(f'loading... training category : {i}')\n",
    "    path=os.path.join(datadir_train,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,3))\n",
    "        flat_data_arr_train.append(img_resized.flatten())\n",
    "        target_arr_train.append(Categories.index(i))\n",
    "    print(f'loaded training category:{i} successfully')\n",
    "flat_data_train=np.array(flat_data_arr_train)\n",
    "target_train=np.array(target_arr_train)\n",
    "df_train=pd.DataFrame(flat_data_train) #dataframe\n",
    "df_train['Target']=target_train\n",
    "x_train=df_train.iloc[:,:-1] #input data\n",
    "y_train=df_train.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57133a49",
   "metadata": {},
   "source": [
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ba3d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading... test category : FAKE\n",
      "loaded test category:FAKE successfully\n",
      "loading... test category : REAL\n",
      "loaded test category:REAL successfully\n"
     ]
    }
   ],
   "source": [
    "flat_data_arr_test=[] #input array\n",
    "target_arr_test=[] #output array\n",
    "#path which contains all of the training images\n",
    "datadir_test = \"C:/Users/Msalek/Documents/Stevens/EE695/Final Project/Code/test\"\n",
    "for i in Categories:\n",
    "    print(f'loading... test category : {i}')\n",
    "    path=os.path.join(datadir_test,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,3))\n",
    "        flat_data_arr_test.append(img_resized.flatten())\n",
    "        target_arr_test.append(Categories.index(i))\n",
    "    print(f'loaded test category:{i} successfully')\n",
    "flat_data_test=np.array(flat_data_arr_test)\n",
    "target_test=np.array(target_arr_test)\n",
    "df_test=pd.DataFrame(flat_data_test) #dataframe\n",
    "df_test['Target']=target_test\n",
    "x_test=df_test.iloc[:,:-1] #input data\n",
    "y_test=df_test.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2016d0b",
   "metadata": {},
   "source": [
    "In order to select the best parameters a smaller data set is used to decrease the required run time\n",
    "\n",
    "This will utilize 500 Fake and 500 Real for the training set and 150 Fake and 150 Real for the test set\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee566ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading... small training category : FAKE_small\n",
      "loaded small training category:FAKE_small successfully\n",
      "loading... small training category : REAL_small\n",
      "loaded small training category:REAL_small successfully\n"
     ]
    }
   ],
   "source": [
    "Categories_small=['FAKE_small','REAL_small']\n",
    "flat_data_arr_train_small=[] #input array\n",
    "target_arr_train_small=[] #output array\n",
    "#path which contains all of the training images\n",
    "datadir_train_small = \"C:/Users/Msalek/Documents/Stevens/EE695/Final Project/Code/train\"\n",
    "for i in Categories_small:\n",
    "    print(f'loading... small training category : {i}')\n",
    "    path=os.path.join(datadir_train_small,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,3))\n",
    "        flat_data_arr_train_small.append(img_resized.flatten())\n",
    "        target_arr_train_small.append(Categories_small.index(i))\n",
    "    print(f'loaded small training category:{i} successfully')\n",
    "flat_data_train_small=np.array(flat_data_arr_train_small)\n",
    "target_train_small=np.array(target_arr_train_small)\n",
    "df_train_small=pd.DataFrame(flat_data_train_small) #dataframe\n",
    "df_train_small['Target']=target_train_small\n",
    "x_train_small=df_train_small.iloc[:,:-1] #input data\n",
    "y_train_small=df_train_small.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03869e7",
   "metadata": {},
   "source": [
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b0bdfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading... small test category : FAKE_small\n",
      "loaded small test category:FAKE_small successfully\n",
      "loading... small test category : REAL_small\n",
      "loaded small test category:REAL_small successfully\n"
     ]
    }
   ],
   "source": [
    "flat_data_arr_test_small=[] #input array\n",
    "target_arr_test_small=[] #output array\n",
    "#path which contains all of the training images\n",
    "datadir_test_small = \"C:/Users/Msalek/Documents/Stevens/EE695/Final Project/Code/test\"\n",
    "for i in Categories_small:\n",
    "    print(f'loading... small test category : {i}')\n",
    "    path=os.path.join(datadir_test_small,i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=imread(os.path.join(path,img))\n",
    "        img_resized=resize(img_array,(150,150,3))\n",
    "        flat_data_arr_test_small.append(img_resized.flatten())\n",
    "        target_arr_test_small.append(Categories_small.index(i))\n",
    "    print(f'loaded small test category:{i} successfully')\n",
    "flat_data_test_small=np.array(flat_data_arr_test_small)\n",
    "target_test_small=np.array(target_arr_test_small)\n",
    "df_test_small=pd.DataFrame(flat_data_test_small) #dataframe\n",
    "df_test_small['Target']=target_test_small\n",
    "x_test_small=df_test_small.iloc[:,:-1] #input data\n",
    "y_test_small=df_test_small.iloc[:,-1] #output data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1f63e",
   "metadata": {},
   "source": [
    "The below code prepares the SVM model to select the best parameters using the smaller data set\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6992d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf']}\n",
    "svc=svm.SVC(probability=True)\n",
    "model_small=GridSearchCV(svc,param_grid,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a181ac",
   "metadata": {},
   "source": [
    "The below code fits the model utilizing the smaller set of training data utilizing all of the parameter options\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4c9ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time= 2.2min\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time= 2.2min\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time= 2.1min\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time= 2.1min\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 2.3min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 2.2min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 2.2min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 2.3min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 2.3min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 2.3min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 2.3min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 2.2min\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time= 1.8min\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time= 1.8min\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time= 1.9min\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time= 1.9min\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time= 1.8min\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time= 2.2min\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time= 2.2min\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 2.2min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 2.2min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 2.3min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 2.2min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 1.9min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 1.9min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 1.8min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 1.8min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 1.7min\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time= 2.2min\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time= 2.2min\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time= 2.2min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 2.2min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 2.2min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time= 1.8min\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time= 1.8min\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time= 1.8min\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time= 1.8min\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time= 1.7min\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time= 2.2min\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time= 2.1min\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time= 2.0min\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time= 2.0min\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time= 2.0min\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time= 2.1min\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time= 2.3min\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time= 2.3min\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time= 2.2min\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time= 2.3min\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time= 2.3min\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time= 2.2min\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time= 2.2min\n",
      "Model training complete\n"
     ]
    }
   ],
   "source": [
    "x_train_small=df_train_small.iloc[:,:-1] #input data\n",
    "y_train_small=df_train_small.iloc[:,-1] #output data\n",
    "\n",
    "x_test_small=df_test_small.iloc[:,:-1] #input data\n",
    "y_test_small=df_test_small.iloc[:,-1] #output data\n",
    "\n",
    "model_small.fit(x_train_small,y_train_small)\n",
    "print('Model training complete')\n",
    "# model.best_params_ contains the best parameters obtained from GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84261c54",
   "metadata": {},
   "source": [
    "Looking at the accuracy on the small test set using the model trained on the small training set\n",
    "\n",
    "This also shows the best parameters found by GridSearchCV\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99d7111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted Data is :\n",
      "[0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0\n",
      " 0 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 1 1]\n",
      "The actual data is:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1]\n",
      "The small model is 72.0% accurate\n",
      "The best parameters are: \n",
      "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_small=model_small.predict(x_test_small)\n",
    "print(\"The predicted Data is :\")\n",
    "print(y_pred_small)\n",
    "print(\"The actual data is:\")\n",
    "print(np.array(y_test_small))\n",
    "print(f\"The small model is {accuracy_score(y_pred_small,y_test_small)*100}% accurate\")\n",
    "\n",
    "print(\"The best parameters are: \")\n",
    "print(model_small.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669280c2",
   "metadata": {},
   "source": [
    "The below code prepares the SVM model to use the best parameters found on the entire dataset\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0aa0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'C':[10],'gamma':[0.0001],'kernel':['rbf']}\n",
    "svc=svm.SVC(probability=True)\n",
    "model=GridSearchCV(svc,param_grid,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d42bab",
   "metadata": {},
   "source": [
    "The below code fits the model utilizing the the full set of training data using the best parameters selected\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772eae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=rbf; total time=138.1min\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=rbf; total time=130.2min\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=rbf; total time=135.6min\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=rbf; total time=127.2min\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=rbf; total time=131.7min\n",
      "Model training complete\n"
     ]
    }
   ],
   "source": [
    "x_train=df_train.iloc[:,:-1] #input data\n",
    "y_train=df_train.iloc[:,-1] #output data\n",
    "\n",
    "x_test=df_test.iloc[:,:-1] #input data\n",
    "y_test=df_test.iloc[:,-1] #output data\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "print('Model training complete')\n",
    "# model.best_params_ contains the best parameters obtained from GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271ccca",
   "metadata": {},
   "source": [
    "Look at the accuracy of the model using the test set\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da78cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted Data is :\n",
      "[0 0 0 ... 1 1 1]\n",
      "The actual data is:\n",
      "[0 0 0 ... 1 1 1]\n",
      "The model is 79.0% accurate\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "print(\"The predicted Data is :\")\n",
    "print(y_pred)\n",
    "print(\"The actual data is:\")\n",
    "print(np.array(y_test))\n",
    "print(f\"The model is {accuracy_score(y_pred,y_test)*100}% accurate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d2026",
   "metadata": {},
   "source": [
    "# Loading in the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf5a189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Currently using 5k real and 5k fake images for the training set because it was too much data to upload to Colab\n",
    "#The test set consists of 1.5k real images and 1.5k fake images\n",
    "real_folder_0 = \"C:/Users/Msalek/Documents/Stevens/EE695/Final Project/Code/train/REAL\"\n",
    "fake_folder_0 = \"C:/Users/Msalek/Documents/Stevens/EE695/Final Project/Code/train/FAKE\"\n",
    "\n",
    "test_real_folder = \"C:/Users/Msalek/Documents/Stevens/EE695/Final Project/Code/test/REAL\"\n",
    "test_fake_folder = \"C:/Users/Msalek/Documents/Stevens/EE695/Final Project/Code/test/FAKE\"\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image = cv2.imread(os.path.join(folder, filename))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            images.append(image)\n",
    "            labels.append(\"1\" if \"REAL\" in folder else \"0\")  # Assign labels based on the folder name\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# Load real images and labels\n",
    "real_images, real_labels = load_images_from_folder(real_folder_0)\n",
    "\n",
    "# Load fake images and labels\n",
    "fake_images, fake_labels = load_images_from_folder(fake_folder_0)\n",
    "\n",
    "# Combine real and fake images and labels\n",
    "training_images = np.concatenate((real_images, fake_images), axis=0)\n",
    "training_labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Shuffle the training set\n",
    "np.random.seed(random_seed)\n",
    "shuffle_indices = np.random.permutation(len(training_images))\n",
    "training_images = training_images[shuffle_indices]\n",
    "training_labels = training_labels[shuffle_indices]\n",
    "\n",
    "# Combine the training set\n",
    "combined_data = list(zip(training_images, training_labels))\n",
    "#Tuples of images and labels\n",
    "training_images, training_labels = zip(*combined_data)\n",
    "\n",
    "#Convert the images and labels back into NumPy arrays for further processing\n",
    "training_images = np.array(training_images)\n",
    "training_labels = np.array(training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bf50d1",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "Perform geometry augmentation shifts and use a Pre-trained CNN to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c2ed6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow.keras.applications as keras_applications\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define image dimensions\n",
    "image_size = (32, 32)\n",
    "\n",
    "# Define the geometry augmentation parameters\n",
    "augmentation_params = {\n",
    "    \"flip\": True,\n",
    "    \"shift_range\": 0.2\n",
    "}\n",
    "\n",
    "def apply_geometry_augmentations(images, labels, augmentation_params):\n",
    "    datagen = ImageDataGenerator(\n",
    "        horizontal_flip=augmentation_params[\"flip\"],\n",
    "        width_shift_range=augmentation_params[\"shift_range\"],\n",
    "        height_shift_range=augmentation_params[\"shift_range\"]\n",
    "    )\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    for image, label in zip(images, labels):\n",
    "        augmented_images.append(image)\n",
    "        augmented_labels.append(label)\n",
    "        if augmentation_params[\"flip\"]:\n",
    "            flipped_image = cv2.flip(image, 1)\n",
    "            augmented_images.append(flipped_image)\n",
    "            augmented_labels.append(label)\n",
    "        if augmentation_params[\"shift_range\"]:\n",
    "            shifted_image = datagen.random_transform(image)\n",
    "            augmented_images.append(shifted_image)\n",
    "            augmented_labels.append(label)\n",
    "    return augmented_images, augmented_labels\n",
    "\n",
    "\n",
    "\n",
    "# Load real images and labels for the test set\n",
    "test_real_images, test_real_labels = load_images_from_folder(test_real_folder)\n",
    "test_fake_images, test_fake_labels = load_images_from_folder(test_fake_folder)\n",
    "\n",
    "# Combine real and fake images and labels for the test set\n",
    "test_images = np.concatenate((test_real_images, test_fake_images), axis=0)\n",
    "test_labels = np.concatenate((test_real_labels, test_fake_labels), axis=0)\n",
    "\n",
    "# Load pre-trained MobileNetV2 model (without the top classifier)\n",
    "model = keras_applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "# Reshape the images to match the input shape of MobileNetV2\n",
    "reshaped_training_images = []\n",
    "for image in training_images:\n",
    "    resized_image = resize(image, image_size)\n",
    "    reshaped_training_images.append(resized_image)\n",
    "reshaped_training_images = np.array(reshaped_training_images)\n",
    "\n",
    "reshaped_test_images = []\n",
    "for image in test_images:\n",
    "    resized_image = resize(image, image_size)\n",
    "    reshaped_test_images.append(resized_image)\n",
    "reshaped_test_images = np.array(reshaped_test_images)\n",
    "\n",
    "# Flatten the images to use as input features for the KNN classifier\n",
    "X_train = reshaped_training_images.reshape(len(reshaped_training_images), -1)\n",
    "Y_train = training_labels\n",
    "X_test = reshaped_test_images.reshape(len(reshaped_test_images), -1)\n",
    "Y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f45157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[0.41176471 0.42745098 0.3372549  ... 0.03921569 0.03137255 0.03529412]\n",
      " [0.29411765 0.29411765 0.24705882 ... 0.42745098 0.45490196 0.38431373]\n",
      " [0.99607843 0.99607843 0.99607843 ... 0.62352941 0.61960784 0.64313725]\n",
      " ...\n",
      " [0.23529412 0.23529412 0.20392157 ... 0.23137255 0.23921569 0.18431373]\n",
      " [0.44705882 0.44705882 0.43921569 ... 0.44313725 0.42745098 0.42352941]\n",
      " [0.98039216 0.94117647 0.98431373 ... 0.23529412 0.4        0.39215686]]\n",
      "X_test:\n",
      "[[9.49019608e-01 9.76470588e-01 9.45098039e-01 ... 7.92156863e-01\n",
      "  7.13725490e-01 6.19607843e-01]\n",
      " [7.68627451e-01 9.41176471e-02 1.39322105e-16 ... 1.21568627e-01\n",
      "  1.17647059e-01 1.01960784e-01]\n",
      " [2.90196078e-01 3.88235294e-01 1.64705882e-01 ... 6.43137255e-01\n",
      "  4.54901961e-01 4.47058824e-01]\n",
      " ...\n",
      " [1.56862745e-01 1.56862745e-01 1.09803922e-01 ... 2.74509804e-02\n",
      "  2.35294118e-02 7.84313725e-03]\n",
      " [9.25490196e-01 9.25490196e-01 9.25490196e-01 ... 6.90196078e-01\n",
      "  8.00000000e-01 7.45098039e-01]\n",
      " [5.52941176e-01 6.23529412e-01 7.01960784e-01 ... 1.92156863e-01\n",
      "  2.82352941e-01 2.50980392e-01]]\n",
      "Y_train:\n",
      "['0' '1' '1' ... '0' '1' '0']\n",
      "Y_test:\n",
      "['1' '1' '1' ... '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\")\n",
    "print(X_train[:10])\n",
    "print(\"X_test:\")\n",
    "print(X_test[:10])\n",
    "print(\"Y_train:\")\n",
    "print(Y_train)\n",
    "print(\"Y_test:\")\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e97a10",
   "metadata": {},
   "source": [
    "The below code prepares the SVM model for the preprocessed input to use the best parameters found using the small data set\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7747150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid={'C':[10],'gamma':[0.0001],'kernel':['rbf']}\n",
    "svc=svm.SVC(probability=True)\n",
    "model_pre=GridSearchCV(svc,param_grid,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72ddb1",
   "metadata": {},
   "source": [
    "The below code fits the model for preprocessed data utilizing the the full set of training data\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70bbeecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 8.8min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 8.9min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 8.7min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 8.8min\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time= 8.6min\n",
      "Preprocessed Model training complete\n"
     ]
    }
   ],
   "source": [
    "model_pre.fit(X_train,Y_train)\n",
    "print('Preprocessed Model training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a1e0b",
   "metadata": {},
   "source": [
    "Look at the accuracy of the preprocessed model using the test set\n",
    "\n",
    "written by Michael Salek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e66fc27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted Data is :\n",
      "['1' '0' '1' ... '0' '1' '0']\n",
      "The actual data is:\n",
      "['1' '1' '1' ... '0' '0' '0']\n",
      "The model is 70.39999999999999% accurate\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Y_pred=model_pre.predict(X_test)\n",
    "print(\"The predicted Data is :\")\n",
    "print(Y_pred)\n",
    "print(\"The actual data is:\")\n",
    "print(np.array(Y_test))\n",
    "print(f\"The model is {accuracy_score(Y_pred,Y_test)*100}% accurate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
