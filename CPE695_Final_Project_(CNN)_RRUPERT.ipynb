{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlazPuz_TC_E"
      },
      "source": [
        "# CPE695 Final Project for Team 1: <br>\n",
        "**Group Members**: Ronald \"Joey\" Rupert, Andrew Greensweight, Michael Salek <br><br>\n",
        "**Problem Statement:** <br>\n",
        "The quality of AI-generated images has rapidly increased, leading to concerns of authenticity and trustworthiness. The aim of this project is to investigate whether computer vision techniques can effectively detect when images have been generated by AI. By addressing this problem, we can contribute to the development of algorithms that enhance the authenticity verification of images.\n",
        "<br>\n",
        "<br>\n",
        "**Information on Dataset:** <br>\n",
        " https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\n",
        "The dataset contains two classes - REAL and FAKE. For REAL, the images are collected from Krizhevsky & Hinton's CIFAR-10 dataset. For the FAKE images, they were generated to be the  equivalent of CIFAR-10 with Stable Diffusion version 1.4.There are 100,000 images for training (50k per class) and 20,000 for testing (10k per class).\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNBj9x9lTyJx"
      },
      "source": [
        "# Loading in the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2ezynIsTBcB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "87af577c-a3c2-4d68-9df4-05809437ea38"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-27c282b49957>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Load real images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mreal_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_folder_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Load fake images and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-27c282b49957>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CPE 695 - Summer 2023/Smaller Dataset for Final Project/real_0'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import datasets, layers, models, losses\n",
        "from google.colab import drive\n",
        "\n",
        "#Currently using 20k real and 20k fake images for the training set because it was too much data to upload to Colab\n",
        "#The test set consists of 8k real images and 8k fake images\n",
        "real_folder_0 = \"/content/drive/MyDrive/CPE 695 - Summer 2023/Smaller Dataset for Final Project/real_0\"\n",
        "fake_folder_0 = \"/content/drive/MyDrive/CPE 695 - Summer 2023/Smaller Dataset for Final Project/fake_0\"\n",
        "\n",
        "test_real_folder = \"/content/drive/MyDrive/CPE 695 - Summer 2023/Smaller Dataset for Final Project/test_real_0\"\n",
        "test_fake_folder = \"/content/drive/MyDrive/CPE 695 - Summer 2023/Smaller Dataset for Final Project/test_fake_0\"\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            image = cv2.imread(os.path.join(folder, filename))\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "            images.append(image)\n",
        "            labels.append(\"real\" if \"real\" in folder else \"fake\")  # Assign labels based on the folder name\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "# Load real images and labels\n",
        "real_images, real_labels = load_images_from_folder(real_folder_0)\n",
        "\n",
        "# Load fake images and labels\n",
        "fake_images, fake_labels = load_images_from_folder(fake_folder_0)\n",
        "\n",
        "# Combine real and fake images and labels\n",
        "training_images = np.concatenate((real_images, fake_images), axis=0)\n",
        "training_labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "random_seed = 42\n",
        "\n",
        "# Shuffle the training set\n",
        "np.random.seed(random_seed)\n",
        "shuffle_indices = np.random.permutation(len(training_images))\n",
        "training_images = training_images[shuffle_indices]\n",
        "training_labels = training_labels[shuffle_indices]\n",
        "\n",
        "# Combine the training set\n",
        "combined_data = list(zip(training_images, training_labels))\n",
        "#Tuples of images and labels\n",
        "training_images, training_labels = zip(*combined_data)\n",
        "\n",
        "#Convert the images and labels back into NumPy arrays for further processing\n",
        "training_images = np.array(training_images)\n",
        "training_labels = np.array(training_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing\n",
        "Perform geometry augmentation shifts and use a Pre-trained CNN to extract features"
      ],
      "metadata": {
        "id": "QQ0kAGcuIKWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At1boh8jI6sR",
        "outputId": "9c573006-4d49-4870-9bd5-a7f1e628c8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "import tensorflow.keras.applications as keras_applications\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define image dimensions\n",
        "image_size = (32, 32)\n",
        "\n",
        "# Define the geometry augmentation parameters\n",
        "augmentation_params = {\n",
        "    \"flip\": True,\n",
        "    \"shift_range\": 0.2\n",
        "}\n",
        "\n",
        "def apply_geometry_augmentations(images, labels, augmentation_params):\n",
        "    datagen = ImageDataGenerator(\n",
        "        horizontal_flip=augmentation_params[\"flip\"],\n",
        "        width_shift_range=augmentation_params[\"shift_range\"],\n",
        "        height_shift_range=augmentation_params[\"shift_range\"]\n",
        "    )\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "    for image, label in zip(images, labels):\n",
        "        augmented_images.append(image)\n",
        "        augmented_labels.append(label)\n",
        "        if augmentation_params[\"flip\"]:\n",
        "            flipped_image = cv2.flip(image, 1)\n",
        "            augmented_images.append(flipped_image)\n",
        "            augmented_labels.append(label)\n",
        "        if augmentation_params[\"shift_range\"]:\n",
        "            shifted_image = datagen.random_transform(image)\n",
        "            augmented_images.append(shifted_image)\n",
        "            augmented_labels.append(label)\n",
        "    return augmented_images, augmented_labels\n",
        "\n",
        "\n",
        "\n",
        "# Load real images and labels for the test set\n",
        "test_real_images, test_real_labels = load_images_from_folder(test_real_folder)\n",
        "test_fake_images, test_fake_labels = load_images_from_folder(test_fake_folder)\n",
        "\n",
        "# Combine real and fake images and labels for the test set\n",
        "test_images = np.concatenate((test_real_images, test_fake_images), axis=0)\n",
        "test_labels = np.concatenate((test_real_labels, test_fake_labels), axis=0)\n",
        "\n",
        "# Load pre-trained MobileNetV2 model (without the top classifier)\n",
        "model = keras_applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(image_size[0], image_size[1], 3))\n",
        "\n",
        "# Reshape the images to match the input shape of MobileNetV2\n",
        "reshaped_training_images = []\n",
        "for image in training_images:\n",
        "    resized_image = resize(image, image_size)\n",
        "    reshaped_training_images.append(resized_image)\n",
        "reshaped_training_images = np.array(reshaped_training_images)\n",
        "\n",
        "reshaped_test_images = []\n",
        "for image in test_images:\n",
        "    resized_image = resize(image, image_size)\n",
        "    reshaped_test_images.append(resized_image)\n",
        "reshaped_test_images = np.array(reshaped_test_images)\n",
        "\n",
        "# Flatten the images to use as input features for the KNN classifier\n",
        "X_train = reshaped_training_images.reshape(len(reshaped_training_images), -1)\n",
        "y_train = training_labels\n",
        "X_test = reshaped_test_images.reshape(len(reshaped_test_images), -1)\n",
        "y_test = test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QC2A_rhII-N",
        "outputId": "dbcc98e5-194f-4c30-c5b7-4af29e3e5dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train:\")\n",
        "print(X_train[:10])\n",
        "print(\"X_test:\")\n",
        "print(X_test[:10])"
      ],
      "metadata": {
        "id": "nKW1U4CtSsSn",
        "outputId": "f7d6f900-af9e-47e0-b597-35b34eabaaf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:\n",
            "[[0.11372549 0.08235294 0.         ... 0.23921569 0.21960784 0.        ]\n",
            " [1.         0.59215686 0.01568627 ... 0.21568627 0.1254902  0.09411765]\n",
            " [0.70588235 0.74509804 0.78039216 ... 0.38039216 0.44705882 0.50980392]\n",
            " ...\n",
            " [0.79215686 0.79215686 0.8        ... 0.48627451 0.48627451 0.49411765]\n",
            " [0.03137255 0.05490196 0.01568627 ... 0.37254902 0.27058824 0.14117647]\n",
            " [0.43137255 0.54901961 0.69803922 ... 0.29803922 0.39607843 0.42352941]]\n",
            "X_test:\n",
            "[[0.36470588 0.2627451  0.17254902 ... 0.52941176 0.41568627 0.28235294]\n",
            " [0.82352941 0.81176471 0.75294118 ... 0.43529412 0.54509804 0.38431373]\n",
            " [0.81960784 0.76470588 0.72941176 ... 0.58823529 0.65098039 0.54901961]\n",
            " ...\n",
            " [0.20392157 0.33333333 0.29803922 ... 0.20784314 0.25882353 0.15686275]\n",
            " [0.98823529 0.89803922 0.86666667 ... 0.97647059 0.85098039 0.70196078]\n",
            " [0.94901961 0.94117647 0.98431373 ... 0.08235294 0.09019608 0.07058824]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Build and fit CNN model, RJR"
      ],
      "metadata": {
        "id": "sgHa7LTBRqWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(reshaped_training_images, training_labels, epochs=10,\n",
        "                    validation_data=(reshaped_test_images, test_labels))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(reshaped_test_images,  test_labels, verbose=2)\n",
        "\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "sT0EAYmgRJ1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9068ce51-4d9e-45ee-8740-ac2db97dbf84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                65600     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}